{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OYywvC3a8o5D"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Function for preprocessing monitored data\n",
    "def load_and_preprocess_mon(file_path):\n",
    "    USE_SUBLABEL = False # Whether to use sub-labeling for detailed pages\n",
    "    URL_PER_SITE = 10 # Number of URLs per monitored site\n",
    "    TOTAL_URLS = 950  # Total monitored URLs (95 classes x 10 subpages)\n",
    "\n",
    "    with open(file_path, 'rb') as fi:\n",
    "        data = pickle.load(fi)\n",
    "\n",
    "    X1, X2, y = [], [], [] # Stores time sequences, size sequences, and labels\n",
    "    additional_features = {\n",
    "        'num_incoming': [], # Number of incoming packets\n",
    "        'num_outgoing': [], # Number of outgoing packets\n",
    "        'total_packets': [], # Total number of packets\n",
    "        'average_packet_interval': [], # Average interval between packets\n",
    "        'std_packet_interval': [], # Standard deviation of packet intervals\n",
    "        'total_data_in': [], # Total size of incoming data\n",
    "        'total_data_out': [] # Total size of outgoing data\n",
    "    }\n",
    "\n",
    "    for i in range(TOTAL_URLS):\n",
    "        label = i if USE_SUBLABEL else i // URL_PER_SITE\n",
    "        for sample in data[i]:\n",
    "            size_seq, time_seq = [], []\n",
    "            incoming, outgoing = 0, 0\n",
    "            for c in sample:\n",
    "                dr = 1 if c > 0 else -1 # Determine packet direction (outgoing=1, incoming=-1)\n",
    "                time_seq.append(abs(c))\n",
    "                size_seq.append(dr * 512)\n",
    "                if dr > 0:\n",
    "                    outgoing += 1\n",
    "                else:\n",
    "                    incoming += 1\n",
    "\n",
    "            X1.append(time_seq)\n",
    "            X2.append(size_seq)\n",
    "            y.append(label)\n",
    "\n",
    "            # additional feature extraction\n",
    "            additional_features['num_incoming'].append(incoming)\n",
    "            additional_features['num_outgoing'].append(outgoing)\n",
    "            additional_features['total_packets'].append(len(time_seq))\n",
    "            additional_features['average_packet_interval'].append(\n",
    "                np.mean(np.diff(time_seq)) if len(time_seq) > 1 else 0\n",
    "            )\n",
    "            additional_features['std_packet_interval'].append(\n",
    "                np.std(np.diff(time_seq)) if len(time_seq) > 1 else 0\n",
    "            )\n",
    "            additional_features['total_data_in'].append(sum([abs(s) for s in size_seq if s < 0]))\n",
    "            additional_features['total_data_out'].append(sum([abs(s) for s in size_seq if s > 0]))\n",
    "\n",
    "    # Normalization\n",
    "    # Convert to values between 0 and 1 for better SVM and Random Forest performance\n",
    "    scaler = MinMaxScaler()\n",
    "    for key in additional_features:\n",
    "        additional_features[key] = scaler.fit_transform(\n",
    "            np.array(additional_features[key]).reshape(-1, 1)\n",
    "        ).flatten()\n",
    "\n",
    "    return (\n",
    "        np.array(X1, dtype=object),\n",
    "        np.array(X2, dtype=object),\n",
    "        np.array(y),\n",
    "        additional_features\n",
    "    )\n",
    "\n",
    "# Function for preprocessing unmonitored data\n",
    "def load_and_preprocess_unmon(file_path):\n",
    "    TOTAL_URLS = 3000  # Total number of unmonitored URLs\n",
    "\n",
    "    with open(file_path, 'rb') as fi:\n",
    "        data = pickle.load(fi)\n",
    "\n",
    "    X1, X2 = [], []\n",
    "    additional_features = {\n",
    "        'num_incoming': [],\n",
    "        'num_outgoing': [],\n",
    "        'total_packets': [],\n",
    "        'average_packet_interval': [],\n",
    "        'std_packet_interval': [],\n",
    "        'total_data_in': [],\n",
    "        'total_data_out': []\n",
    "    }\n",
    "\n",
    "    for i in range(TOTAL_URLS):\n",
    "        size_seq, time_seq = [], []\n",
    "        incoming, outgoing = 0, 0\n",
    "        for c in data[i]:\n",
    "            dr = 1 if c > 0 else -1\n",
    "            time_seq.append(abs(c))\n",
    "            size_seq.append(dr * 512)\n",
    "            if dr > 0:\n",
    "                outgoing += 1\n",
    "            else:\n",
    "                incoming += 1\n",
    "\n",
    "        X1.append(time_seq)\n",
    "        X2.append(size_seq)\n",
    "\n",
    "        # additional feature extraction\n",
    "        additional_features['num_incoming'].append(incoming)\n",
    "        additional_features['num_outgoing'].append(outgoing)\n",
    "        additional_features['total_packets'].append(len(time_seq))\n",
    "        additional_features['average_packet_interval'].append(\n",
    "            np.mean(np.diff(time_seq)) if len(time_seq) > 1 else 0\n",
    "        )\n",
    "        additional_features['std_packet_interval'].append(\n",
    "            np.std(np.diff(time_seq)) if len(time_seq) > 1 else 0\n",
    "        )\n",
    "        additional_features['total_data_in'].append(sum([abs(s) for s in size_seq if s < 0]))\n",
    "        additional_features['total_data_out'].append(sum([abs(s) for s in size_seq if s > 0]))\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    for key in additional_features:\n",
    "        additional_features[key] = scaler.fit_transform(\n",
    "            np.array(additional_features[key]).reshape(-1, 1)\n",
    "        ).flatten()\n",
    "\n",
    "    return (\n",
    "        np.array(X1, dtype=object),\n",
    "        np.array(X2, dtype=object),\n",
    "        additional_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZbSx84K68rIX",
    "outputId": "566efb72-a6f9-4cf5-b7e7-acdf5553fcb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed-world Monitored data saved as processed_mon_data_closed_world.pkl\n",
      "Closed-world Monitored Data Sample:\n",
      "                                                time_seq  \\\n",
      "0      [0.0, 0.14, 0.14, 0.31, 0.31, 0.51, 0.51, 0.51...   \n",
      "1      [0.0, 0.13, 0.13, 0.31, 0.77, 1.11, 1.11, 1.11...   \n",
      "2      [0.0, 0.11, 0.11, 0.23, 0.97, 1.11, 1.11, 1.11...   \n",
      "3      [0.0, 0.27, 0.27, 0.6, 0.6, 0.88, 0.89, 0.89, ...   \n",
      "4      [0.0, 0.11, 0.11, 0.36, 0.36, 0.6, 0.6, 0.6, 0...   \n",
      "...                                                  ...   \n",
      "18995  [0.0, 0.15, 0.15, 0.33, 0.91, 1.12, 1.13, 1.13...   \n",
      "18996  [0.0, 0.16, 0.16, 0.35, 0.99, 1.26, 1.26, 1.26...   \n",
      "18997  [0.0, 0.11, 0.11, 0.36, 0.36, 0.83, 0.83, 0.83...   \n",
      "18998  [0.0, 0.17, 0.17, 0.32, 1.98, 2.56, 2.56, 2.56...   \n",
      "18999  [0.0, 0.12, 0.12, 0.46, 0.46, 0.72, 0.73, 0.73...   \n",
      "\n",
      "                                                size_seq  label  num_incoming  \\\n",
      "0      [-512, -512, 512, -512, 512, -512, 512, 512, -...      0      0.131810   \n",
      "1      [-512, -512, 512, -512, 512, -512, 512, 512, -...      0      0.042696   \n",
      "2      [-512, -512, 512, -512, 512, -512, 512, 512, -...      0      0.125607   \n",
      "3      [-512, -512, 512, -512, 512, -512, 512, 512, -...      0      0.134291   \n",
      "4      [-512, -512, 512, -512, 512, -512, 512, 512, -...      0      0.130880   \n",
      "...                                                  ...    ...           ...   \n",
      "18995  [-512, -512, 512, -512, 512, -512, 512, 512, -...     94      0.908715   \n",
      "18996  [-512, -512, 512, -512, 512, -512, 512, 512, -...     94      0.969606   \n",
      "18997  [-512, -512, 512, -512, 512, -512, 512, 512, -...     94      0.966401   \n",
      "18998  [-512, -512, 512, -512, 512, -512, 512, 512, -...     94      0.952238   \n",
      "18999  [-512, -512, 512, -512, 512, -512, 512, 512, -...     94      0.945208   \n",
      "\n",
      "       num_outgoing  total_packets  avg_packet_interval  std_packet_interval  \\\n",
      "0          0.027155       0.137886             0.005112             0.004693   \n",
      "1          0.017473       0.047068             0.014701             0.020769   \n",
      "2          0.026446       0.131550             0.005914             0.008032   \n",
      "3          0.027391       0.140400             0.006725             0.005563   \n",
      "4          0.025738       0.136377             0.005444             0.004378   \n",
      "...             ...            ...                  ...                  ...   \n",
      "18995      0.144746       0.943780             0.003207             0.018154   \n",
      "18996      0.128926       0.996279             0.000841             0.001851   \n",
      "18997      0.135301       0.995876             0.000790             0.001452   \n",
      "18998      0.161511       0.993262             0.001177             0.003661   \n",
      "18999      0.177332       0.993161             0.000702             0.000753   \n",
      "\n",
      "       total_data_in  total_data_out  \n",
      "0           0.131810        0.027155  \n",
      "1           0.042696        0.017473  \n",
      "2           0.125607        0.026446  \n",
      "3           0.134291        0.027391  \n",
      "4           0.130880        0.025738  \n",
      "...              ...             ...  \n",
      "18995       0.908715        0.144746  \n",
      "18996       0.969606        0.128926  \n",
      "18997       0.966401        0.135301  \n",
      "18998       0.952238        0.161511  \n",
      "18999       0.945208        0.177332  \n",
      "\n",
      "[19000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preparing and saving Closed-world monitored data\n",
    "mon_path = \"./mon_standard.pkl\" # Path to the monitored data file\n",
    "X1_mon, X2_mon, y_mon, features_mon = load_and_preprocess_mon(mon_path)\n",
    "\n",
    "# Save the processed monitored data\n",
    "mon_data = {\n",
    "    'X1': X1_mon, # Time sequences\n",
    "    'X2': X2_mon, # Size sequences\n",
    "    'y': y_mon, # Labels\n",
    "    'features': features_mon # Additional extracted features\n",
    "}\n",
    "\n",
    "with open(\"./processed_mon_data_closed_world.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mon_data, f)\n",
    "\n",
    "print(\"Closed-world Monitored data saved as processed_mon_data_closed_world.pkl\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df_mon = pd.DataFrame({\n",
    "    'time_seq': X1_mon,\n",
    "    'size_seq': X2_mon,\n",
    "    'label': y_mon,\n",
    "    'num_incoming': features_mon['num_incoming'],\n",
    "    'num_outgoing': features_mon['num_outgoing'],\n",
    "    'total_packets': features_mon['total_packets'],\n",
    "    'avg_packet_interval': features_mon['average_packet_interval'],\n",
    "    'std_packet_interval': features_mon['std_packet_interval'],\n",
    "    'total_data_in': features_mon['total_data_in'],\n",
    "    'total_data_out': features_mon['total_data_out']\n",
    "})\n",
    "\n",
    "print(\"Closed-world Monitored Data Sample:\")\n",
    "print(df_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xX1cea88t6m",
    "outputId": "baa6eef1-4352-4469-90e1-4e2fc3dcb79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-world Binary data saved as processed_binary_data_open_world.pkl\n",
      "Open-world Binary Data Sample:\n",
      "                                                time_seq  \\\n",
      "0      [0.0, 0.14, 0.14, 0.31, 0.31, 0.51, 0.51, 0.51...   \n",
      "1      [0.0, 0.13, 0.13, 0.31, 0.77, 1.11, 1.11, 1.11...   \n",
      "2      [0.0, 0.11, 0.11, 0.23, 0.97, 1.11, 1.11, 1.11...   \n",
      "3      [0.0, 0.27, 0.27, 0.6, 0.6, 0.88, 0.89, 0.89, ...   \n",
      "4      [0.0, 0.11, 0.11, 0.36, 0.36, 0.6, 0.6, 0.6, 0...   \n",
      "...                                                  ...   \n",
      "21995  [0.0, 0.1, 0.1, 0.22, 0.79, 0.95, 0.96, 1.09, ...   \n",
      "21996  [0.0, 0.17, 0.17, 0.37, 1.73, 2.23, 2.23, 2.56...   \n",
      "21997  [0.0, 0.11, 0.11, 0.23, 0.86, 1.18, 1.18, 1.5,...   \n",
      "21998  [0.0, 0.17, 0.17, 0.35, 3.07, 3.28, 3.28, 3.71...   \n",
      "21999  [0.0, 0.13, 0.13, 0.35, 0.98, 1.46, 1.46, 1.9,...   \n",
      "\n",
      "                                                size_seq  label  num_incoming  \\\n",
      "0      [-512, -512, 512, -512, 512, -512, 512, 512, -...    1.0      0.131810   \n",
      "1      [-512, -512, 512, -512, 512, -512, 512, 512, -...    1.0      0.042696   \n",
      "2      [-512, -512, 512, -512, 512, -512, 512, 512, -...    1.0      0.125607   \n",
      "3      [-512, -512, 512, -512, 512, -512, 512, 512, -...    1.0      0.134291   \n",
      "4      [-512, -512, 512, -512, 512, -512, 512, 512, -...    1.0      0.130880   \n",
      "...                                                  ...    ...           ...   \n",
      "21995  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.292116   \n",
      "21996  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.348340   \n",
      "21997  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.360788   \n",
      "21998  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.400415   \n",
      "21999  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.945332   \n",
      "\n",
      "       num_outgoing  total_packets  avg_packet_interval  std_packet_interval  \\\n",
      "0          0.027155       0.137886             0.005112             0.004693   \n",
      "1          0.017473       0.047068             0.014701             0.020769   \n",
      "2          0.026446       0.131550             0.005914             0.008032   \n",
      "3          0.027391       0.140400             0.006725             0.005563   \n",
      "4          0.025738       0.136377             0.005444             0.004378   \n",
      "...             ...            ...                  ...                  ...   \n",
      "21995      0.111316       0.318712             0.004177             0.006800   \n",
      "21996      0.058571       0.355936             0.003902             0.006498   \n",
      "21997      0.089543       0.378169             0.002829             0.004060   \n",
      "21998      0.144128       0.434507             0.006282             0.031034   \n",
      "21999      0.232137       0.991851             0.001045             0.001602   \n",
      "\n",
      "       total_data_in  total_data_out  \n",
      "0           0.131810        0.027155  \n",
      "1           0.042696        0.017473  \n",
      "2           0.125607        0.026446  \n",
      "3           0.134291        0.027391  \n",
      "4           0.130880        0.025738  \n",
      "...              ...             ...  \n",
      "21995       0.292116        0.111316  \n",
      "21996       0.348340        0.058571  \n",
      "21997       0.360788        0.089543  \n",
      "21998       0.400415        0.144128  \n",
      "21999       0.945332        0.232137  \n",
      "\n",
      "[22000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preparing and saving Open-world Binary data\n",
    "mon_path = \"./mon_standard.pkl\" # Path to the monitored data file\n",
    "unmon_path = \"./unmon_standard10_3000.pkl\" # Path to the unmonitored data file\n",
    "\n",
    "X1_mon, X2_mon, y_mon, features_mon = load_and_preprocess_mon(mon_path)\n",
    "X1_unmon, X2_unmon, features_unmon = load_and_preprocess_unmon(unmon_path)\n",
    "\n",
    "# Monitored label: 1, Unmonitored label: -1\n",
    "y_mon_binary = np.ones(len(y_mon))\n",
    "y_unmon_binary = -1 * np.ones(len(X1_unmon))\n",
    "\n",
    "# Merge monitored and unmonitored data\n",
    "X1 = np.concatenate((X1_mon, X1_unmon))\n",
    "X2 = np.concatenate((X2_mon, X2_unmon))\n",
    "y = np.concatenate((y_mon_binary, y_unmon_binary))\n",
    "\n",
    "# Merge additional features\n",
    "features = {key: np.concatenate((features_mon[key], features_unmon[key])) for key in features_mon}\n",
    "\n",
    "# Save the merged data\n",
    "binary_data = {\n",
    "    'X1': X1,\n",
    "    'X2': X2,\n",
    "    'y': y,\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "with open(\"./processed_binary_data_open_world.pkl\", \"wb\") as f:\n",
    "    pickle.dump(binary_data, f)\n",
    "\n",
    "print(\"Open-world Binary data saved as processed_binary_data_open_world.pkl\")\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_binary = pd.DataFrame({\n",
    "    'time_seq': X1,\n",
    "    'size_seq': X2,\n",
    "    'label': y, # Monitored label (1) / Unmonitored label (-1)\n",
    "    'num_incoming': features['num_incoming'],\n",
    "    'num_outgoing': features['num_outgoing'],\n",
    "    'total_packets': features['total_packets'],\n",
    "    'avg_packet_interval': features['average_packet_interval'],\n",
    "    'std_packet_interval': features['std_packet_interval'],\n",
    "    'total_data_in': features['total_data_in'],\n",
    "    'total_data_out': features['total_data_out']\n",
    "})\n",
    "\n",
    "print(\"Open-world Binary Data Sample:\")\n",
    "print(df_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Gzmg_CS8xGz",
    "outputId": "fae0950b-7c70-43fe-a4de-f3af5914d14d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-world Multi-class data saved as processed_multiclass_data_open_world.pkl\n",
      "Open-world Multi-class Data Sample:\n",
      "                                                time_seq  \\\n",
      "0      [0.0, 0.14, 0.14, 0.31, 0.31, 0.51, 0.51, 0.51...   \n",
      "1      [0.0, 0.13, 0.13, 0.31, 0.77, 1.11, 1.11, 1.11...   \n",
      "2      [0.0, 0.11, 0.11, 0.23, 0.97, 1.11, 1.11, 1.11...   \n",
      "3      [0.0, 0.27, 0.27, 0.6, 0.6, 0.88, 0.89, 0.89, ...   \n",
      "4      [0.0, 0.11, 0.11, 0.36, 0.36, 0.6, 0.6, 0.6, 0...   \n",
      "...                                                  ...   \n",
      "21995  [0.0, 0.1, 0.1, 0.22, 0.79, 0.95, 0.96, 1.09, ...   \n",
      "21996  [0.0, 0.17, 0.17, 0.37, 1.73, 2.23, 2.23, 2.56...   \n",
      "21997  [0.0, 0.11, 0.11, 0.23, 0.86, 1.18, 1.18, 1.5,...   \n",
      "21998  [0.0, 0.17, 0.17, 0.35, 3.07, 3.28, 3.28, 3.71...   \n",
      "21999  [0.0, 0.13, 0.13, 0.35, 0.98, 1.46, 1.46, 1.9,...   \n",
      "\n",
      "                                                size_seq  label  num_incoming  \\\n",
      "0      [-512, -512, 512, -512, 512, -512, 512, 512, -...    0.0      0.131810   \n",
      "1      [-512, -512, 512, -512, 512, -512, 512, 512, -...    0.0      0.042696   \n",
      "2      [-512, -512, 512, -512, 512, -512, 512, 512, -...    0.0      0.125607   \n",
      "3      [-512, -512, 512, -512, 512, -512, 512, 512, -...    0.0      0.134291   \n",
      "4      [-512, -512, 512, -512, 512, -512, 512, 512, -...    0.0      0.130880   \n",
      "...                                                  ...    ...           ...   \n",
      "21995  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.292116   \n",
      "21996  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.348340   \n",
      "21997  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.360788   \n",
      "21998  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.400415   \n",
      "21999  [-512, -512, 512, -512, 512, -512, 512, -512, ...   -1.0      0.945332   \n",
      "\n",
      "       num_outgoing  total_packets  avg_packet_interval  std_packet_interval  \\\n",
      "0          0.027155       0.137886             0.005112             0.004693   \n",
      "1          0.017473       0.047068             0.014701             0.020769   \n",
      "2          0.026446       0.131550             0.005914             0.008032   \n",
      "3          0.027391       0.140400             0.006725             0.005563   \n",
      "4          0.025738       0.136377             0.005444             0.004378   \n",
      "...             ...            ...                  ...                  ...   \n",
      "21995      0.111316       0.318712             0.004177             0.006800   \n",
      "21996      0.058571       0.355936             0.003902             0.006498   \n",
      "21997      0.089543       0.378169             0.002829             0.004060   \n",
      "21998      0.144128       0.434507             0.006282             0.031034   \n",
      "21999      0.232137       0.991851             0.001045             0.001602   \n",
      "\n",
      "       total_data_in  total_data_out  \n",
      "0           0.131810        0.027155  \n",
      "1           0.042696        0.017473  \n",
      "2           0.125607        0.026446  \n",
      "3           0.134291        0.027391  \n",
      "4           0.130880        0.025738  \n",
      "...              ...             ...  \n",
      "21995       0.292116        0.111316  \n",
      "21996       0.348340        0.058571  \n",
      "21997       0.360788        0.089543  \n",
      "21998       0.400415        0.144128  \n",
      "21999       0.945332        0.232137  \n",
      "\n",
      "[22000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preparing and saving Open-world Multi-class data\n",
    "mon_path = \"./mon_standard.pkl\" # Path to the monitored data file\n",
    "unmon_path = \"./unmon_standard10_3000.pkl\" # Path to the unmonitored data file\n",
    "\n",
    "X1_mon, X2_mon, y_mon, features_mon = load_and_preprocess_mon(mon_path)\n",
    "X1_unmon, X2_unmon, features_unmon = load_and_preprocess_unmon(unmon_path)\n",
    "\n",
    "# Monitored labels: 0 to 94, Unmonitored label: -1\n",
    "y_unmon_multi = -1 * np.ones(len(X1_unmon))\n",
    "\n",
    "# Merge monitored and unmonitored data\n",
    "X1 = np.concatenate((X1_mon, X1_unmon))\n",
    "X2 = np.concatenate((X2_mon, X2_unmon))\n",
    "y = np.concatenate((y_mon, y_unmon_multi))\n",
    "\n",
    "# Merge additional features\n",
    "features = {key: np.concatenate((features_mon[key], features_unmon[key])) for key in features_mon}\n",
    "\n",
    "# Save the merged data\n",
    "multi_class_data = {\n",
    "    'X1': X1,\n",
    "    'X2': X2,\n",
    "    'y': y,\n",
    "    'features': features\n",
    "}\n",
    "\n",
    "with open(\"./processed_multiclass_data_open_world.pkl\", \"wb\") as f:\n",
    "    pickle.dump(multi_class_data, f)\n",
    "\n",
    "print(\"Open-world Multi-class data saved as processed_multiclass_data_open_world.pkl\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df_multiclass = pd.DataFrame({\n",
    "    'time_seq': X1,\n",
    "    'size_seq': X2,\n",
    "    'label': y,\n",
    "    'num_incoming': features['num_incoming'],\n",
    "    'num_outgoing': features['num_outgoing'],\n",
    "    'total_packets': features['total_packets'],\n",
    "    'avg_packet_interval': features['average_packet_interval'],\n",
    "    'std_packet_interval': features['std_packet_interval'],\n",
    "    'total_data_in': features['total_data_in'],\n",
    "    'total_data_out': features['total_data_out']\n",
    "})\n",
    "\n",
    "print(\"Open-world Multi-class Data Sample:\")\n",
    "print(df_multiclass)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
